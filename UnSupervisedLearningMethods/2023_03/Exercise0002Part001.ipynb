{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/qkg2E2D.png)\n",
    "\n",
    "# UnSupervised Learning Methods\n",
    "\n",
    "## Exercise 002 - Part I\n",
    "\n",
    "> Notebook by:\n",
    "> - Royi Avital RoyiAvital@fixelalgorithms.com\n",
    "\n",
    "## Revision History\n",
    "\n",
    "| Version | Date       | User        |Content / Changes                                                   |\n",
    "|---------|------------|-------------|--------------------------------------------------------------------|\n",
    "| 0.1.001 | 04/05/2023 | Royi Avital | Fixed the missing squares in `1.1`                                 |\n",
    "| 0.1.000 | 31/03/2023 | Royi Avital | First version                                                      |\n",
    "|         |            |             |                                                                    |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/FixelAlgorithmsTeam/FixelCourses/blob/master/UnSupervisedLearningMethods/2023_03/Exercise0002Part001.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notations\n",
    "\n",
    "* <font color='red'>(**?**)</font> Question to answer interactively.\n",
    "* <font color='blue'>(**!**)</font> Simple task to add code for the notebook.\n",
    "* <font color='green'>(**@**)</font> Optional / Extra self practice.\n",
    "* <font color='brown'>(**#**)</font> Note / Useful resource / Food for thought."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guidelines\n",
    "\n",
    " - Fill the full names of the team memebers in the `Team Members` section.\n",
    " - Answer all questions within the Jupyter Notebook.\n",
    " - Open questions are in part I of the exercise.\n",
    " - Coding based questions are in the subsequent notebooks.\n",
    " - Use MarkDown + MathJaX + Code to answer.\n",
    " - Submission in groups (Single submission per group).\n",
    " - You may and _should_ use the forums for question.\n",
    " - Good Luck!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Members\n",
    "\n",
    " - `<FULL>_<NAME>_<001>`.\n",
    " - `<FULL>_<NAME>_<002>`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Linear Algebra\n",
    "\n",
    "The Frobenius Norm ${\\left\\| \\cdot \\right\\|}_{F} : \\mathbb{R}^{m \\times n} \\to \\mathbb{R}^{+}$ is defined as ${\\left\\| A \\right\\|}_{F} = \\sqrt{\\sum_{i} \\sum_{j} {A}_{ij}^{2}}$.\n",
    "\n",
    "### 1.1. Question\n",
    "\n",
    "Let $A \\in \\mathbb{R}^{m \\times n}$ and ${\\lambda}_{i} \\left( M \\right)$ is the $i$ -th eigen value of the matrix $M$ (Assuming $M$ has a valid eigen decomposition).  \n",
    "Prove that ${\\left\\| A \\right\\|}_{F}^{2} = \\sum_{i = 1}^{n} {\\lambda}_{i} \\left( {A}^{T} A \\right)$.  \n",
    "\n",
    "* <font color='brown'>(**#**)</font> Make sure to show why ${\\lambda}_{i} \\left( {A}^{T} A \\right)$ exists."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Solution\n",
    "\n",
    "<font color='red'>??? Fill the answer here ???</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A matrix $Q \\in \\mathbb{R}^{n \\times n}$ is called a positive definite matrix if and only if $\\forall \\boldsymbol{x} \\in \\mathbb{R}^{n} \\setminus \\left\\{ \\boldsymbol{0} \\right\\}, \\; \\boldsymbol{x}^{T} Q \\boldsymbol{x} > \\boldsymbol{0}$.\n",
    "\n",
    "* <font color='brown'>(**#**)</font> The following are the common notations:\n",
    "    * $\\boldsymbol{S}^{N}      = \\left\\{ X \\in \\mathbb{R}^{n \\times n} \\mid X = {X}^{T} \\right\\}$ (Symmetric matrices).\n",
    "    * $\\boldsymbol{S}^{N}_{+}  = \\left\\{ X \\in \\mathbb{R}^{n \\times n} \\mid X \\succeq 0 \\right\\}$ (Positive semi definite matrices which are symmetric).\n",
    "    * $\\boldsymbol{S}^{N}_{++} = \\left\\{ X \\in \\mathbb{R}^{n \\times n} \\mid X \\succ 0 \\right\\}$ (Positive definite matrices which are symmetric).\n",
    "\n",
    "### 1.2. Question\n",
    "\n",
    "Let $Q \\in \\mathbb{R}^{n \\times n}$ be a positive definite matrix. Show that ${\\left\\| \\boldsymbol{x} \\right\\|}_{Q} = \\sqrt{\\boldsymbol{x}^{T} Q \\boldsymbol{x}}$ is a norm."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Solution\n",
    "\n",
    "<font color='red'>??? Fill the answer here ???</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A matrix $U \\in \\mathbb{R}^{n \\times n}$ is called an _orthogonal matrix_ if and only if ${U}^{T} U = U {U}^{T} = {U}^{-1} U = U {U}^{-1} = I$.\n",
    "\n",
    "* <font color='brown'>(**#**)</font> For matrices over $\\mathbb{C}$ we call such matrices a unitary matrices.\n",
    "\n",
    "### 1.3. Question\n",
    "\n",
    "Show that for any orthogonal matrix $U$ is an isometry with respect to the euclidean norm, that is ${\\left\\| U \\boldsymbol{x} \\right\\|}_{2} = {\\left\\| x \\right\\|}_{2}$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Solution\n",
    "\n",
    "<font color='red'>??? Fill the answer here ???</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matrix $R = \\begin{bmatrix*}[r] \\cos \\left( \\theta \\right) & - \\sin \\left( \\theta \\right) \\\\ \\sin \\left( \\theta \\right) & \\cos \\left( \\theta \\right) \\end{bmatrix*}$ is called a rotation matrix.\n",
    "\n",
    "### 1.4. Question\n",
    "\n",
    "For the set of matrices of size $2 \\times 2$, Prove or disprove:\n",
    "\n",
    " - The matrix $R$ is a orthogonal matrix.\n",
    " - Any orthogonal matrix is a rotation matrix."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Solution\n",
    "\n",
    "<font color='red'>??? Fill the answer here ???</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Optimization\n",
    "\n",
    "A twice differentiable function is convex if and only if ${\\nabla}^{2} f \\left( \\boldsymbol{x} \\right) \\succeq 0$. \n",
    "\n",
    "### 2.1. Question\n",
    "\n",
    "Consider the function $f \\left( \\boldsymbol{x} \\right) : \\mathbb{R}^{n}_{++} \\to \\mathbb{R}_{-}$ where $f \\left( \\boldsymbol{x} \\right) = -\\sqrt[^n]{ {x}_{1} {x}_{2} \\ldots {x}_{n} }$.  \n",
    "Show that $ f\\left( \\boldsymbol{x} \\right)$ is a convex function."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Solution\n",
    "\n",
    "<font color='red'>??? Fill the answer here ???</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Question\n",
    "\n",
    "Find the global minimum and maximum points of the linear function $f \\left( x, y \\right) = 7 x + 12 y$ over the set $\\mathcal{S} = \\left\\{ \\left( x, y \\right) \\mid 2 {x}^{2} + 6 x y + 9 {y}^{2} - 2 x - 6 y \\leq 24 \\right\\}$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Solution\n",
    "\n",
    "<font color='red'>??? Fill the answer here ???</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. K-Means\n",
    "\n",
    "The K-Means objective is given by:\n",
    "\n",
    "$$ \\arg \\min_{ \\left\\{ \\mathcal{D}_{k} \\right\\}, \\left\\{ {\\boldsymbol{\\mu}}_{k} \\right\\} } \\sum_{k = 1}^{K} \\sum_{ \\boldsymbol{x}_{i} \\in \\mathcal{D}_{k} } {\\left\\| \\boldsymbol{x}_{i} - \\boldsymbol{\\mu}_{k} \\right\\|}_{2}^{2} $$\n",
    "\n",
    "### 3.1. Question\n",
    "\n",
    "Show that the following 2 objectives are equivalent to the K-Means objectives:\n",
    "\n",
    "1. As a function of the clusters:\n",
    "\n",
    "$$ \\arg \\min_{ \\left\\{ \\mathcal{D}_{k} \\right\\} } \\sum_{k = 1}^{K} \\frac{1}{\\left| \\mathcal{D}_{k} \\right|} \\sum_{ \\boldsymbol{x}_{i}, \\boldsymbol{x}_{j} \\in \\mathcal{D}_{k} } {\\left\\| \\boldsymbol{x}_{i} - \\boldsymbol{x}_{j} \\right\\|}_{2}^{2} $$\n",
    "\n",
    "2. As a function of the centroids:\n",
    "\n",
    "$$ \\arg \\min_{ \\left\\{ {\\boldsymbol{\\mu}}_{k} \\right\\} } \\sum_{i = 1}^{N} \\min_{k} {\\left\\| \\boldsymbol{x}_{i} - \\boldsymbol{\\mu}_{k} \\right\\|}_{2}^{2} $$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Solution\n",
    "\n",
    "<font color='red'>??? Fill the answer here ???</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Question\n",
    "\n",
    "Prove or disprove: The K-Means algorithm **always** converge to a global minimum."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Solution\n",
    "\n",
    "<font color='red'>??? Fill the answer here ???</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Gaussian Mixture Model\n",
    "\n",
    " * Let $\\underline{X} \\sim \\mathcal{N}_{d} \\left( \\boldsymbol{\\mu}_{x}, {\\Sigma}_{x} \\right)$ be a Gaussian Radom Vector.\n",
    " * Let $Y = {\\boldsymbol{a}}^{T} \\underline{X} + b$ be a random variable.\n",
    "\n",
    "\n",
    "### 4.1. Question\n",
    "\n",
    "Find ${f}_{Y} \\left( y \\right)$, the Probability Density Function (PDF) of $Y$ as a function of $\\boldsymbol{\\mu}_{x}, {\\Sigma}_{x}, \\boldsymbol{a}, b$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Solution\n",
    "\n",
    "<font color='red'>??? Fill the answer here ???</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A matrix $A \\in \\mathbb{R}^{d \\times d}$ is called Symmetric Positive Semi Definite (SPSD) if ${A}^{T} = A$ and for any $\\boldsymbol{v} \\in \\mathbb{R}^{d}$:\n",
    "\n",
    "$$ \\boldsymbol{v}^{T} A \\boldsymbol{v} \\geq 0 $$\n",
    "\n",
    "### 4.2. Question\n",
    "\n",
    "Let $\\underline{X}$ be a random vector with covariance matrix ${\\Sigma}_{x}$. Show that ${\\Sigma}_{x}$ is an SPSD matrix."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>??? Fill the answer here ???</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Hierarchical Clustering\n",
    "\n",
    "The _complete linkage distance_ between the 2 clusters $\\mathcal{C}_{1} = {\\left\\{ \\boldsymbol{x}_{i} \\right\\}}_{i = 1}^{{N}_{1}}$ and $\\mathcal{C}_{2} = {\\left\\{ \\boldsymbol{x}_{j} \\right\\}}_{j = 1}^{{N}_{2}}$:\n",
    "\n",
    "$$ {d}^{2}_{\\text{Complete Link}} \\left( \\mathcal{C}_{1}, \\mathcal{C}_{2} \\right) = \\begin{cases}\n",
    "0 & \\text{ if } \\mathcal{C}_{1} = \\mathcal{C}_{2} \\\\ \n",
    "\\max_{\\boldsymbol{x}_{i} \\in \\mathcal{C}_{1}, \\boldsymbol{x}_{j} \\in \\mathcal{C}_{2}} \\left\\| \\boldsymbol{x}_{i} - \\boldsymbol{x}_{j} \\right\\| & \\text{ if } \\mathcal{C}_{1} \\neq \\mathcal{C}_{2}\n",
    "\\end{cases} $$\n",
    "\n",
    "### 5.1. Question\n",
    "\n",
    "Prove that the complete linkage is indeed a metric."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Solution\n",
    "\n",
    "<font color='red'>??? Fill the answer here ???</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * The _single linkage dissimilarity_ between the 2 clusters $\\mathcal{C}_{1} = {\\left\\{ \\boldsymbol{x}_{i} \\right\\}}_{i = 1}^{{N}_{1}}$ and $\\mathcal{C}_{2} = {\\left\\{ \\boldsymbol{x}_{j} \\right\\}}_{j = 1}^{{N}_{2}}$:\n",
    "\n",
    "$$ {d}^{2}_{\\text{Single Link}} \\left( \\mathcal{C}_{1}, \\mathcal{C}_{2} \\right) = \\min_{\\boldsymbol{x}_{i} \\in \\mathcal{C}_{1}, \\boldsymbol{x}_{j} \\in \\mathcal{C}_{2}} \\left\\| \\boldsymbol{x}_{i} - \\boldsymbol{x}_{j} \\right\\| $$\n",
    "\n",
    " * The _Lance Williams_ update rule is given by: ${D}_{\\overline{ij}, k} = {\\alpha}_{i} {D}_{i, k} + {\\alpha}_{j} {D}_{j, k} + \\beta {D}_{i, j} + \\gamma \\left| {D}_{i, k} - {D}_{j, k} \\right|$.\n",
    "\n",
    "### 5.2. Question\n",
    "\n",
    "Consider 3 clusters $\\mathcal{C}_{1}, \\mathcal{C}_{2}, \\mathcal{C}_{3}$ with ${D}_{i, j} = {d}_{\\text{Single Link}} \\left( \\mathcal{C}_{i}, \\mathcal{C}_{j} \\right)$.  \n",
    "Prove that:\n",
    "\n",
    "$$ {D}_{\\overline{12}, 3} = {d}_{\\text{Single Link}} \\left( \\mathcal{C}_{1} \\cup \\mathcal{C}_{2}, \\mathcal{C}_{3} \\right) $$\n",
    "\n",
    "In other words, show that the _Lance Williams_ algorithm is correct for the _single linkage dissimilarity_."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Solution\n",
    "\n",
    "<font color='red'>??? Fill the answer here ???</font>\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "39577bab1f263e62e0b74f5b8086bd735049bf4751f6562b2d4b2969dc308293"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
