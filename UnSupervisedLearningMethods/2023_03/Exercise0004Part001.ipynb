{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/qkg2E2D.png)\n",
    "\n",
    "# UnSupervised Learning Methods\n",
    "\n",
    "## Exercise 004 - Part I\n",
    "\n",
    "> Notebook by:\n",
    "> - Royi Avital RoyiAvital@fixelalgorithms.com\n",
    "\n",
    "## Revision History\n",
    "\n",
    "| Version | Date       | User        |Content / Changes                                                   |\n",
    "|---------|------------|-------------|--------------------------------------------------------------------|\n",
    "| 0.1.000 | 11/06/2023 | Royi Avital | First version                                                      |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/FixelAlgorithmsTeam/FixelCourses/blob/master/UnSupervisedLearningMethods/2023_03/Exercise0004Part001.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notations\n",
    "\n",
    "* <font color='red'>(**?**)</font> Question to answer interactively.\n",
    "* <font color='blue'>(**!**)</font> Simple task to add code for the notebook.\n",
    "* <font color='green'>(**@**)</font> Optional / Extra self practice.\n",
    "* <font color='brown'>(**#**)</font> Note / Useful resource / Food for thought."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guidelines\n",
    "\n",
    " - Fill the full names and ID's of the team members in the `Team Members` section.\n",
    " - Answer all questions / tasks within the Jupyter Notebook.\n",
    " - Use MarkDown + MathJaX + Code to answer.\n",
    " - Verify the rendering on VS Code.\n",
    " - Submission in groups (Single submission per group).\n",
    " - You may and _should_ use the forums for questions.\n",
    " - Good Luck!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Members\n",
    "\n",
    " - `<FULL>_<NAME>_<ID001>`.\n",
    " - `<FULL>_<NAME>_<ID002>`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Classic Multi Dimensional Scaling (MDS)\n",
    "\n",
    " * Given a function $ \\phi \\left( \\cdot \\right) : \\mathbb{R}^{D} \\to \\mathbb{R}^{M} $.\n",
    " * Consider the following inner product: ${\\left \\langle \\boldsymbol{x}, \\boldsymbol{y} \\right \\rangle}_{\\phi} = \\left \\langle \\phi \\left( \\boldsymbol{x} \\right), \\phi \\left( \\boldsymbol{y} \\right) \\right \\rangle$.\n",
    " * Yields the induced norm: $ {\\left\\| \\boldsymbol{x} \\right\\|}_{\\phi} = \\sqrt{ \\left \\langle \\phi \\left( \\boldsymbol{x} \\right), \\phi \\left( \\boldsymbol{x} \\right) \\right \\rangle } $.\n",
    " * Yields the induced metric: ${d}_{\\phi} \\left( \\boldsymbol{x}, \\boldsymbol{y} \\right) = {\\left\\| \\boldsymbol{x} - \\boldsymbol{y} \\right\\|}_{\\phi}$.\n",
    "\n",
    "### 1.1. Question\n",
    "\n",
    "Consider the data (Training set) $\\mathcal{X} = \\left\\{ \\boldsymbol{x}_{i} \\in \\mathcal{R}^{D} \\right\\}_{i = 1}^{N}$ and let $\\boldsymbol{D}_{\\phi} \\left[ i, j \\right] = {d}_{\\phi}^{2} \\left( \\boldsymbol{x}_{i}, \\boldsymbol{x}_{j} \\right)$.\n",
    "\n",
    "Show that $- \\frac{1}{2} \\boldsymbol{J} \\boldsymbol{D}_{\\phi} \\boldsymbol{J} = J \\boldsymbol{K}_{\\phi} \\boldsymbol{J}$ where:\n",
    "\n",
    " * $\\boldsymbol{J} = \\boldsymbol{I} - \\frac{1}{N} \\boldsymbol{1} \\boldsymbol{1}^{T}$ - The centering matrix.\n",
    " * $\\boldsymbol{K}_{\\phi} = \\boldsymbol{\\Phi}^{T} \\boldsymbol{\\Phi}$ where: $\\boldsymbol{\\Phi} = \\begin{bmatrix} \\mid & \\mid &  & \\mid \\\\ \\phi \\left( \\boldsymbol{x}_{1} \\right) & \\phi \\left( \\boldsymbol{x}_{2} \\right) & \\dots & \\phi \\left( \\boldsymbol{x}_{N} \\right) \\\\ \\mid & \\mid & & \\mid \\end{bmatrix} \\in \\mathbb{R}^{M \\times N} = \\boldsymbol{\\Phi} = \\begin{bmatrix} \\mid & \\mid &  & \\mid \\\\ \\boldsymbol{\\phi}_{1} & \\boldsymbol{\\phi}_{2} & \\dots & \\boldsymbol{\\phi}_{N} \\\\ \\mid & \\mid & & \\mid \\end{bmatrix} \\in \\mathbb{R}^{M \\times N}$.\n",
    "\n",
    "* <font color='brown'>(**#**)</font> Hints:\n",
    "    * Show that the transformation $\\phi \\left( \\cdot \\right)$ must be linear: $\\phi \\left( \\alpha \\boldsymbol{x}, \\beta \\boldsymbol{y} \\right) = \\alpha \\phi \\left( \\boldsymbol{x} \\right) + \\beta \\phi \\left( \\boldsymbol{y} \\right)$.  \n",
    "      You may use $\\left \\langle \\alpha \\boldsymbol{x} + \\beta \\boldsymbol{y}, \\boldsymbol{z} \\right \\rangle$ as a starting point. \n",
    "    * Show that ${d}_{\\phi}^{2} \\left( \\boldsymbol{x}, \\boldsymbol{y} \\right) = {\\left\\| \\phi \\left( \\boldsymbol{x} \\right) - \\phi \\left( \\boldsymbol{y} \\right) \\right\\|}_{2}^{2} = {\\left\\| \\phi \\left( \\boldsymbol{x} \\right) \\right\\|}_{2}^{2} - 2 \\left \\langle \\phi \\left( \\boldsymbol{x} \\right), \\phi \\left( \\boldsymbol{y} \\right) \\right \\rangle + {\\left\\| \\phi \\left( \\boldsymbol{y} \\right) \\right\\|}_{2}^{2}$\n",
    "    * Use the lecture notes to conclude $- \\frac{1}{2} \\boldsymbol{J} \\boldsymbol{D}_{\\phi} \\boldsymbol{J} = J \\boldsymbol{K}_{\\phi} \\boldsymbol{J}$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Solution\n",
    "\n",
    "<font color='red'>??? Fill the answer here ???</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the data (Training set) $\\mathcal{X} = \\left\\{ \\boldsymbol{x}_{i} \\in \\mathcal{R}^{D} \\right\\}_{i = 1}^{N}$ and let $\\boldsymbol{D} \\left[ i, j \\right] = {\\left\\| \\boldsymbol{x}_{i} - \\boldsymbol{x}_{j} \\right\\|}_{2}^{2}$.\n",
    "\n",
    "### 1.2. Question\n",
    "\n",
    "Show that $\\boldsymbol{v}^{T} \\boldsymbol{D} \\boldsymbol{v} \\leq 0$ for any $\\boldsymbol{v}$ such that $\\left \\langle \\boldsymbol{v}, \\boldsymbol{1} \\right \\rangle = 0$.  \n",
    "What does it imply on _distance matrices_?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Solution\n",
    "\n",
    "<font color='red'>??? Fill the answer here ???</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Metric Multi Dimensional Scaling (MDS)\n",
    "\n",
    "The metric MDS objective is given by:\n",
    "\n",
    "$$ \\arg \\min_{\\boldsymbol{Z} \\in \\mathbb{R}^{d \\times N}} {\\left\\| \\boldsymbol{\\Delta}_{x} - \\boldsymbol{D}_{z} \\right\\|}_{F}^{2} $$\n",
    "\n",
    "Where:\n",
    "\n",
    " * $\\boldsymbol{\\Delta}_{x} \\left[ i, j \\right] = d \\left( \\boldsymbol{x}_{i}, \\boldsymbol{x}_{j} \\right)$ - The given distance matrix.\n",
    " * $\\boldsymbol{D}_{z} = {\\left\\| \\boldsymbol{z}_{i} - \\boldsymbol{z}_{j} \\right\\|}_{2}$.\n",
    "\n",
    "Consider the surrogate function:\n",
    "\n",
    "$$ g \\left( \\boldsymbol{Z}, \\tilde{\\boldsymbol{Z}} \\right) = {\\left\\| \\boldsymbol{\\Delta}_{x} \\right\\|}_{F}^{2} + 2 N \\operatorname{Tr} \\left( \\boldsymbol{Z} \\boldsymbol{J} \\boldsymbol{Z}^{T} \\right) - 4 \\left \\langle \\boldsymbol{Z}^{T} \\tilde{\\boldsymbol{Z}}, \\boldsymbol{B} \\right \\rangle $$\n",
    "\n",
    "Where:\n",
    "\n",
    " * $\\boldsymbol{J} = \\boldsymbol{I} - \\frac{1}{N} \\boldsymbol{1} \\boldsymbol{1}^{T}$ - The centering matrix.\n",
    " * $\\tilde{\\boldsymbol{D}}_{\\tilde{z}} \\left[ i, j \\right] = {\\left\\| \\tilde{\\boldsymbol{z}}_{i} - \\tilde{\\boldsymbol{z}}_{j} \\right\\|}_{2}$.\n",
    " * $\\boldsymbol{C} \\left[ i, j \\right] = \\begin{cases} 0 & \\text{ if } i = j \\\\ - \\frac{ \\boldsymbol{\\Delta}_{x} \\left[ i, j \\right] }{ \\tilde{\\boldsymbol{D}}_{z} \\left[ i, j \\right] } & \\text{ if } i \\neq j \\end{cases}$.\n",
    " * $\\boldsymbol{B} = \\boldsymbol{C} - \\operatorname{Diag} \\left( \\boldsymbol{C} \\boldsymbol{1} \\right)$.\n",
    "\n",
    "### 3.1. Question\n",
    "\n",
    "Prove that $ \\boldsymbol{B} \\boldsymbol{J} = \\boldsymbol{B} $."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Solution\n",
    "\n",
    "<font color='red'>??? Fill the answer here ???</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Question\n",
    "\n",
    "Show that $g \\left( \\boldsymbol{Z}, \\boldsymbol{Z} \\right) = {\\left\\| \\boldsymbol{\\Delta}_{x} - \\boldsymbol{D}_{z} \\right\\|}_{F}^{2}$.\n",
    "\n",
    "\n",
    " * <font color='brown'>(**#**)</font> Hints (See _lecture notes_):\n",
    "     * ${\\left\\| \\boldsymbol{\\Delta}_{x} - \\boldsymbol{D}_{z} \\right\\|}_{F}^{2} = {\\left\\| \\boldsymbol{\\Delta}_{x} \\right\\|}_{F}^{2} - 2 \\left \\langle \\boldsymbol{\\Delta}_{x}, \\boldsymbol{D}_{z} \\right \\rangle + {\\left\\| \\boldsymbol{D}_{z} \\right\\|}_{F}^{2}$.\n",
    "     * ${\\left\\| \\boldsymbol{D}_{z} \\right\\|}_{F}^{2} = 2 N \\operatorname{Tr} \\left( \\boldsymbol{Z} \\boldsymbol{J} \\boldsymbol{Z}^{T} \\right)$.\n",
    "     * $\\boldsymbol{D}^{\\circ 2}_{z} \\left[ i, j \\right] = \\boldsymbol{p} \\boldsymbol{1}^{T} - 2 \\boldsymbol{Z}^{T} \\boldsymbol{Z} + 1 \\boldsymbol{p}^{T}, \\; \\boldsymbol{p} = \\begin{bmatrix} {\\left\\| \\boldsymbol{z}_{1} \\right\\|}_{2}^{2} \\\\ {\\left\\| \\boldsymbol{z}_{2} \\right\\|}_{2}^{2} \\\\ \\vdots {\\left\\| \\boldsymbol{z}_{N} \\right\\|}_{2}^{2} \\end{bmatrix}$.\n",
    "     * For $\\tilde{\\boldsymbol{Z}} = \\boldsymbol{Z}$ we have $\\left \\langle \\boldsymbol{\\Delta}_{x}, \\boldsymbol{D}_{z} \\right \\rangle = - \\left \\langle \\boldsymbol{C}, \\boldsymbol{D}^{\\circ 2}_{z} \\right \\rangle$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Solution\n",
    "\n",
    "<font color='red'>??? Fill the answer here ???</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. IsoMap\n",
    "\n",
    "Let $G = \\left( V, E, W \\right) $ be a simple, undirected and weighted graph with no negative weights / edges.  \n",
    "Let $\\boldsymbol{D} \\in \\mathbb{R}^{N \\times N}$ be the shortest path distance matrix where $ \\left| V \\right| = N$.\n",
    "\n",
    "\n",
    "### 4.1. Question\n",
    "\n",
    "Prove or disprove: There is an embedding ${\\left\\{ \\boldsymbol{z}_{i} \\in \\mathbb{R}^{d} \\right\\}}_{i = 1}^{N}$ for some $d \\in \\mathbb{N}$ such that:\n",
    "\n",
    "$$ \\forall i, j \\; \\boldsymbol{D} \\left[ i, j \\right] = {\\left\\| \\boldsymbol{z}_{i} - \\boldsymbol{z}_{j} \\right\\|}_{2} $$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Solution\n",
    "\n",
    "<font color='red'>??? Fill the answer here ???</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Question\n",
    "\n",
    " * Let $\\mathcal{X} = \\left\\{ \\boldsymbol{x}_{i} \\in \\mathbb{R}^{D} \\right\\}_{i = 1}^{N}$ be the training set.\n",
    " * Let $\\mathcal{Z} = \\left\\{ \\boldsymbol{z}_{i} \\right\\}_{i = 1}^{N}$ be the representation obtained by IsoMap (Encoded data).\n",
    " * Consider a new point $\\boldsymbol{x}^{\\ast}$ where $\\boldsymbol{x}^{\\ast} = \\boldsymbol{x}_{k}, \\; k \\in \\left\\{ 1, 2, \\ldots, N \\right\\}$.\n",
    " * Let $\\boldsymbol{z}^{\\ast}$ be the out of sample encoding applied to $\\boldsymbol{x}^{\\ast}$.\n",
    "\n",
    "Prove or disprove: $\\boldsymbol{z}^{\\ast} = \\boldsymbol{z}_{k}$.\n",
    "\n",
    " * <font color='brown'>(**#**)</font> The out of sample encoding is as shown in _lecture notes_.\n",
    " * <font color='brown'>(**#**)</font> The question is basically if the out of sample extension is equivalent to having the point in the training set for such case.\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Solution\n",
    "\n",
    "<font color='red'>??? Fill the answer here ???</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Laplacian Eigenmaps\n",
    "\n",
    " * Let $\\mathcal{X} = \\left\\{ \\boldsymbol{x}_{i} \\in \\mathbb{R}^{D} \\right\\}_{i = 1}^{N}$.\n",
    " * Let $G = \\left( V, E, W \\right)$ be a weighted graph with with $V = \\mathcal{X}$.\n",
    " * Define $\\boldsymbol{W} \\left[ i, j \\right] = \\begin{cases} \\exp \\left( - \\frac{ {\\left\\| \\boldsymbol{x}_{i} - \\boldsymbol{x}_{j} \\right\\|}_{2}^{2} }{2 {\\sigma}^{2}} \\right) & \\text{ if } \\boldsymbol{x}_{i} \\in \\mathcal{N}_{j} \\text{ or } \\boldsymbol{x}_{j} \\in \\mathcal{N}_{i} \\\\ 0 & \\text{ else } \\end{cases}$.\n",
    " * Then ${e}_{ij} \\in E$ if $\\boldsymbol{W} \\left[ i, j \\right] \\neq 0$.\n",
    " * The _Graph Laplacian_ $\\boldsymbol{L} = \\boldsymbol{D} - \\boldsymbol{W}$.\n",
    " * The _Degree Matrix_ $\\boldsymbol{D} = \\operatorname{Diag} \\left( \\boldsymbol{W} \\boldsymbol{1} \\right)$.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume that $G$ has 2 connected components, that is $V = {V}_{1} \\cup {V}_{2}$ such that $\\left\\{ {e}_{ij} \\mid i \\in {V}_{1}, j \\in {V}_{2} \\right\\} = \\emptyset$.\n",
    "\n",
    "### 5.2. Question\n",
    "\n",
    "Show that the _Graph Laplacian_ $\\boldsymbol{L}$ has two **orthogonal** eigenvectors corresponding to the zero eigenvalue.  \n",
    "That is, there are $\\boldsymbol{u}_{1}, \\boldsymbol{u}_{2} \\in \\mathbb{R}^{N}$ such that:\n",
    "\n",
    " * $\\boldsymbol{L} \\boldsymbol{u}_{1} = \\boldsymbol{L} \\boldsymbol{u}_{2} = \\boldsymbol{0}$.\n",
    " * $\\left \\langle \\boldsymbol{u}_{1}, \\boldsymbol{u}_{2} \\right \\rangle = 0$.\n",
    "\n",
    "Explain the meaning of the result, specifically address:\n",
    "\n",
    " * How to do spectral clustering in such case.\n",
    " * How to do dimensionality reduction in such case."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Solution\n",
    "\n",
    "<font color='red'>??? Fill the answer here ???</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. t-SNE (Bonus 4 Points)\n",
    "\n",
    "The t-SNE objective is given by:\n",
    "\n",
    "$$ \\arg \\min_{ \\boldsymbol{Z} \\in \\mathbb{R}^{d \\times N} } f \\left( \\boldsymbol{Z} \\right) = \\arg \\min_{ \\boldsymbol{Z} \\in \\mathbb{R}^{d \\times N} } {D}_{KL} \\left( \\boldsymbol{P} \\mid \\mid \\boldsymbol{Q} \\right) = \\arg \\min_{ \\boldsymbol{Z} \\in \\mathbb{R}^{d \\times N} } \\sum_{i = 1}^{N} \\sum_{j = 1}^{N} {p}_{ij} \\log \\left( \\frac{{p}_{ij}}{{q}_{ij}} \\right) $$\n",
    "\n",
    "Look for the definitions of $\\boldsymbol{P}$ and $\\boldsymbol{Q}$ **in the context of t-SNE** in lecture notes.\n",
    "\n",
    "### 6.1. The t-SNE Objective Gradient\n",
    "\n",
    "In the following sub questions the gradient of the objective function $\\nabla f \\left( \\boldsymbol{Z} \\right)$ will be derived in multiple steps.\n",
    "\n",
    "#### 6.1.1. Question\n",
    "\n",
    "Show that $f \\left( \\boldsymbol{Z} \\right) = {D}_{KL} \\left( \\boldsymbol{P} \\mid \\mid \\boldsymbol{Q} \\right)$ can be written as $f \\left( \\boldsymbol{Z} \\right) = C - \\left \\langle \\boldsymbol{P}, \\log \\left( \\boldsymbol{Q} \\right) \\right \\rangle$ for some constant $c$.\n",
    "\n",
    "* <font color='brown'>(**#**)</font> The constant $C$ above is actually the _Entropy_ of $\\boldsymbol{P}$.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.1. Solution\n",
    "\n",
    "<font color='red'>??? Fill the answer here ???</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * Reminder $\\boldsymbol{Q} \\left[ i, j \\right] = \\frac{1}{B} \\begin{cases} 0 & \\text{ if } i = j \\\\ {\\left( 1 + {\\left\\| \\boldsymbol{z}_{i} - \\boldsymbol{z}_{j} \\right\\|}_{2}^{2} \\right)}^{-1} & \\text{ if } i \\neq j \\end{cases}$.\n",
    " * Let $\\boldsymbol{D}_{z} \\in \\mathbb{R}^{N \\times N}$ where $\\boldsymbol{D}_{z} \\left[ i, j \\right] = {\\left\\| \\boldsymbol{z}_{i} - \\boldsymbol{z}_{j} \\right\\|}_{2}^{2}$.  \n",
    " * Let $\\boldsymbol{S} = {\\left( \\boldsymbol{1} \\boldsymbol{1}^{T} + \\boldsymbol{D}_{z} \\right)}^{\\circ -1} \\in \\mathbb{R}^{N \\times N}$ that is $\\boldsymbol{S} \\left[ i, j \\right] = {\\left( 1 + \\boldsymbol{D}_{z} \\left[ i, j \\right] \\right)}^{-1}$.\n",
    "\n",
    "\n",
    "#### 6.1.2. Question\n",
    "\n",
    "Show that $B = \\boldsymbol{1}^{T} \\left( \\boldsymbol{S} - \\boldsymbol{I} \\right) \\boldsymbol{1} \\in \\mathbb{R}$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.2. Solution\n",
    "\n",
    "<font color='red'>??? Fill the answer here ???</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.3. Question\n",
    "\n",
    "Show that $\\boldsymbol{Q} = \\frac{1}{B} \\left( \\boldsymbol{S} - \\boldsymbol{I} \\right)$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.3. Solution\n",
    "\n",
    "<font color='red'>??? Fill the answer here ???</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.4. Question\n",
    "\n",
    "Show that $- \\left \\langle \\boldsymbol{P}, \\log \\left( \\boldsymbol{Q} \\right) \\right \\rangle = \\log \\left( B \\right) + \\left \\langle \\boldsymbol{P}, \\log \\left( \\boldsymbol{1} \\boldsymbol{1}^{T} + \\boldsymbol{D}_{z} \\right) \\right \\rangle$.\n",
    "\n",
    " * <font color='brown'>(**#**)</font> Think of the value of $\\boldsymbol{P} \\left[ i, i \\right]$ and $\\boldsymbol{1}^{T} \\boldsymbol{P} \\boldsymbol{1}$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.4. Solution\n",
    "\n",
    "<font color='red'>??? Fill the answer here ???</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $f \\left( \\boldsymbol{Z} \\right) = C + \\log \\left( B \\right) + \\left \\langle \\boldsymbol{P}, \\log \\left( \\boldsymbol{1} \\boldsymbol{1}^{T} + \\boldsymbol{D}_{z} \\right) \\right \\rangle$\n",
    "\n",
    "#### 6.1.5. Question\n",
    "\n",
    "Show that ${\\nabla}_{z} \\left \\langle \\boldsymbol{P}, \\log \\left( \\boldsymbol{1} \\boldsymbol{1}^{T} + \\boldsymbol{D}_{z} \\right) \\right \\rangle \\left[ \\boldsymbol{H} \\right] = \\left \\langle \\boldsymbol{S} \\circ \\boldsymbol{P}, {\\nabla}_{z} \\left[ \\boldsymbol{H} \\right] \\right \\rangle$.\n",
    "\n",
    "* <font color='brown'>(**#**)</font> You may use $\\nabla \\boldsymbol{S} \\left[ \\boldsymbol{H} \\right] = \\nabla {\\left( \\boldsymbol{1} \\boldsymbol{1}^{T} + \\boldsymbol{D}_{z} \\right)}^{\\circ -1} \\left[ \\boldsymbol{H} \\right] = - {\\left( \\boldsymbol{1} \\boldsymbol{1}^{T} + \\boldsymbol{D}_{z} \\right)}^{\\circ -2} \\circ \\nabla \\left( \\boldsymbol{D}_{z} \\right) \\left[ \\boldsymbol{H} \\right] = - \\boldsymbol{S} \\circ \\boldsymbol{S} \\circ \\nabla \\left( \\boldsymbol{D}_{z} \\right) \\left[ \\boldsymbol{H} \\right]$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.5. Solution\n",
    "\n",
    "<font color='red'>??? Fill the answer here ???</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 6.1.6. Question\n",
    "\n",
    "Show that ${\\nabla}_{z} \\log \\left( B \\right) = \\left \\langle \\boldsymbol{S} \\circ \\boldsymbol{Q}, \\nabla \\left( \\boldsymbol{D}_{z} \\right) \\left[ \\boldsymbol{H} \\right] \\right \\rangle$.\n",
    "\n",
    "* <font color='brown'>(**#**)</font> You may use $\\boldsymbol{Q} = \\frac{1}{B} \\left( \\boldsymbol{S} - \\boldsymbol{I} \\right)$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.6. Solution\n",
    "\n",
    "<font color='red'>??? Fill the answer here ???</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 6.1.7. Question\n",
    "\n",
    "Combine all previous and writhe the gradient of the objective $\\nabla f \\left( \\boldsymbol{Z} \\right)$.\n",
    "\n",
    "* <font color='brown'>(**#**)</font> You may use $\\boldsymbol{A} = \\left( \\boldsymbol{P} - \\boldsymbol{Q} \\right) \\circ \\boldsymbol{S}$ to simplify the answer."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.7. Solution\n",
    "\n",
    "<font color='red'>??? Fill the answer here ???</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 6.1.8. Question\n",
    "\n",
    "What can you say about the gradient of $\\nabla f \\left( \\boldsymbol{Z} \\right)$ when $\\boldsymbol{P} = \\boldsymbol{Q}$?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.8. Solution\n",
    "\n",
    "<font color='red'>??? Fill the answer here ???</font>\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "39577bab1f263e62e0b74f5b8086bd735049bf4751f6562b2d4b2969dc308293"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
